{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Long Short-term Memory for Text Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team: Buyang Li, Yuxuan Li"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook uses LSTM neural network to generate text from Nietzsche's writings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "import sys\n",
    "import io\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "from tensorflow.keras.utils import get_file\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the data\n",
    "Nietzsche's writing dataset is available online. The following code download the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/text-datasets/nietzsche.txt\n",
      "606208/600901 [==============================] - 2s 3us/step\n",
      "614400/600901 [==============================] - 2s 3us/step\n"
     ]
    }
   ],
   "source": [
    "path = get_file(\n",
    "    'nietzsche.txt',\n",
    "    origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
    "with io.open(path, encoding='utf-8') as f:\n",
    "    text = f.read().lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 600893\n"
     ]
    }
   ],
   "source": [
    "print('corpus length:', len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "supposing that truth is a woman--what then? is there not ground\n",
      "for suspecting that all philosophers, in so far as they have been\n",
      "dogmatists, have failed to understand women--that the terrible\n",
      "seriousness and clumsy importunity with which they have usually paid\n",
      "their addresses to truth, have been unskilled and unseemly methods for\n",
      "winning a woman? certainly she has never allowed herself to be won; and\n",
      "at present every kind of dogma stands with sad and discouraged mien--if,\n",
      "indeed, it stands at all!\n"
     ]
    }
   ],
   "source": [
    "print(text[10:513])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 57\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "# total nomber of characters\n",
    "print('total chars:', len(chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean data\n",
    "\n",
    "We cut the text in sequences of maxlen characters with a jump size of 3.\n",
    "The features for each example is a matrix of size maxlen*num of chars.\n",
    "The label for each example is a vector of size num of chars, which represents the next character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create (character, index) and (index, character) dictionary\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb sequences: 200285\n"
     ]
    }
   ],
   "source": [
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "maxlen = 40\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('nb sequences:', len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jason\\AppData\\Local\\Temp/ipykernel_20100/3587441563.py:2: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
      "C:\\Users\\Jason\\AppData\\Local\\Temp/ipykernel_20100/3587441563.py:3: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n"
     ]
    }
   ],
   "source": [
    "print('Vectorization...')\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the model - fill in this box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(layers.LSTM(units = 128, return_sequences = True, input_shape = (x.shape[1], x.shape[2])))\n",
    "model.add(layers.Dropout(0.2))\n",
    "\n",
    "model.add(layers.LSTM(units = 128, return_sequences = True))\n",
    "model.add(layers.Dropout(0.25))\n",
    "\n",
    "model.add(layers.LSTM(units = 128, return_sequences = True))\n",
    "model.add(layers.Dropout(0.25))\n",
    "\n",
    "model.add(layers.LSTM(units = 128))\n",
    "model.add(layers.Dropout(0.25))\n",
    "\n",
    "model.add(layers.Dense(y.shape[1], activation='softmax'))\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "model.compile(optimizer =optimizer, loss = 'mean_squared_error')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the model\n",
    "\n",
    "Use the `.summary` method to print a simple description of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_21 (LSTM)              (None, 40, 128)           95232     \n",
      "                                                                 \n",
      " dropout_21 (Dropout)        (None, 40, 128)           0         \n",
      "                                                                 \n",
      " lstm_22 (LSTM)              (None, 40, 128)           131584    \n",
      "                                                                 \n",
      " dropout_22 (Dropout)        (None, 40, 128)           0         \n",
      "                                                                 \n",
      " lstm_23 (LSTM)              (None, 40, 128)           131584    \n",
      "                                                                 \n",
      " dropout_23 (Dropout)        (None, 40, 128)           0         \n",
      "                                                                 \n",
      " lstm_24 (LSTM)              (None, 128)               131584    \n",
      "                                                                 \n",
      " dropout_24 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 57)                7353      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 497,337\n",
      "Trainable params: 497,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PrintLoss(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, _):\n",
    "        # Function invoked at end of each epoch. Prints generated text.\n",
    "        print()\n",
    "        print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "        start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "        for diversity in [0.5, 1.0]:\n",
    "            print('----- diversity:', diversity)\n",
    "\n",
    "            generated = ''\n",
    "            sentence = text[start_index: start_index + maxlen]\n",
    "            generated += sentence\n",
    "            print('----- Generating with seed: \"' + sentence + '\"')\n",
    "            sys.stdout.write(generated)\n",
    "\n",
    "            for i in range(400):\n",
    "                x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "                for t, char in enumerate(sentence):\n",
    "                    x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "                preds = model.predict(x_pred, verbose=0)[0]\n",
    "                next_index = sample(preds, diversity)\n",
    "                next_char = indices_char[next_index]\n",
    "\n",
    "                sentence = sentence[1:] + next_char\n",
    "\n",
    "                sys.stdout.write(next_char)\n",
    "                sys.stdout.flush()\n",
    "            print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fill in this box for training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_callbacks = PrintLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "783/783 [==============================] - ETA: 0s - loss: 0.0164\n",
      "----- Generating text after Epoch: 0\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"lthough the science does not dominate,\n",
      "b\"\n",
      "lthough the science does not dominate,\n",
      "be etio fo e reae tienee esmnna oi mopeee  e niemeto ien e heo rttiv arpta tae e sn oa eee ceaes no eltsn eaoe tene  sttt oet  oele  oa ue tesn rrse to he raee ahd tnn maon ese  t]i woih heri es tare ecredtu reei rienot rrot elhid er eeeddh t hitih rn ar a tiat eh no tte h troeso leh  oeae eei trme rit teist eiie aseee rlef atne eed eroe oul oerr faoe sees  alote  aeas ,s itis tos eee ntei ae rrrae\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"lthough the science does not dominate,\n",
      "b\"\n",
      "lthough the science does not dominate,\n",
      "bndiw7e jseohit o;e s,aeoodrl mu(odd dem [lurw,rnfmte wridsesepnorsee hti ryrstgulnt n s:hhf atnil eniao uasetll\n",
      "laa ctevladle thhe hbsnrr\n",
      "lcimle  nzoye (ohtabrnega tgenrl \n",
      " ewtaee ot m= -lennuwrnoe ceodew\n",
      "h'u eeemem e,, [wnle smio tthssa  napaomesusdt owtbtt trethtn taprrcerprr seme !lhdedrptnte opcurncles y7- réearo wv \n",
      "loe ewr yaten au t\"o  xetnc kswotoon ubtu rnmtt mauei\n",
      "ade foldnto o ijra hee,\n",
      "783/783 [==============================] - 380s 485ms/step - loss: 0.0164\n",
      "Epoch 2/5\n",
      "783/783 [==============================] - ETA: 0s - loss: 0.0151\n",
      "----- Generating text after Epoch: 1\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"reatest number,\"--no! the happiness\n",
      "of e\"\n",
      "reatest number,\"--no! the happiness\n",
      "of eor meer yhe to porice in the rose nors the be sieane the unal pate un bas oo mht protecet ne be the fune of the anvey ars doete and is artee and at the ald mas the ooc or the meruc an boane dusd serliths and cis ous is soome and the har the serpe and the the ot the cretlt and the the the eut is os oe remiss oo it mg mare woaur in is the soror the the srat of the eat clreoine af the meprtees meor m\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"reatest number,\"--no! the happiness\n",
      "of e\"\n",
      "reatest number,\"--no! the happiness\n",
      "of egticasld 4e  ylamtfer to srodaree ard whil deeeumëar, andewvtf, andits erllibf pofic cos\n",
      "oe oe bfr\n",
      "etob nicieeicg dlibotorcv bis pisale in anpilluthts ouvsod onoe. he moc hur as is 6hr wore the eminsits-crple rarch oos the\n",
      "thamd lut the\n",
      "obe\n",
      "seelns ois as  eojsy oh ails a thin pomranet hao os eomef lisagcs\n",
      "in ho axoelsse\n",
      "acd the -svcauoirl uf to te mi reoe whame 1g mhi8r,\n",
      "wret\n",
      "nerhbrtjiol oe lterre\n",
      "783/783 [==============================] - 394s 504ms/step - loss: 0.0151\n",
      "Epoch 3/5\n",
      "783/783 [==============================] - ETA: 0s - loss: 0.0141\n",
      "----- Generating text after Epoch: 2\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"\n",
      "\n",
      "\n",
      "85\n",
      "\n",
      "=naughtiness is rare.=--most peop\"\n",
      "\n",
      "\n",
      "\n",
      "85\n",
      "\n",
      "=naughtiness is rare.=--most peope as who sove in is pescannt hre the\n",
      "ave he plelt with is the dere and il the dese which all the the benon in stonter of the caelt and the the peing and cevet to the there the cislt of the at is at the wore sont and the whom the care that it at the sas and art penlased as the wan is the esen the seming in in his ho be conle and the rare hat he conr, at\n",
      "coonter and the gren he mand in derting the m\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"\n",
      "\n",
      "\n",
      "85\n",
      "\n",
      "=naughtiness is rare.=--most peop\"\n",
      "\n",
      "\n",
      "\n",
      "85\n",
      "\n",
      "=naughtiness is rare.=--most peoppeshelt and iw wh merby are at ashem ope\n",
      "adsmatnlr coree it is the alits in the it the aglpds, at the rlisut in oneonm defiass, an the the re rans mas\n",
      "the\n",
      "the dins at selius of il matith to ik aml] with whas amly pebon the meurh selon the the dirlroy he the rupnaesrult\n",
      "in it enky the nuos thit in ould\n",
      "to deys cish im tho\n",
      "t whhin\n",
      "\"exre, ati the ée\n",
      "-ar inheithy hirliphion\n",
      "nroryohhont the mebly\n",
      "as th\n",
      "783/783 [==============================] - 403s 514ms/step - loss: 0.0141\n",
      "Epoch 4/5\n",
      "783/783 [==============================] - ETA: 0s - loss: 0.0135\n",
      "----- Generating text after Epoch: 3\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"oal to which those paths\n",
      "lead? everythin\"\n",
      "oal to which those paths\n",
      "lead? everything and and the gange at the irtun of i with is as the is he the sofs and the mont as the ame itses, at is the  ceansert, and the not of consen at the senible in in anl the more evenkers, insorhing as at a worl for as the male is the sruce and the corkensiwion of as contion, how his the to sreaming to in in ahidhor his the wan as cortion to as the peling which ciseet and out which ann, senning that \n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"oal to which those paths\n",
      "lead? everythin\"\n",
      "oal to which those paths\n",
      "lead? everything and in reebch of hiscorition ince\n",
      "lees,\n",
      "hower pnec has atlerupsions and beinning as. fanled -velnionos with\n",
      "lveed the mume wotef coo-th is in beangs. kavorlt, onor that wime the\n",
      "lruas\" fhom thho im\n",
      "is\n",
      "beelt. the pesy over suchrer g which rpora.h of soathing, that as faass of tho sur, for cotodty nithe for to trot wass, a  runong whature\n",
      "of i -phhiblueilcpe this theyher pep hpother to sove mewer \n",
      "783/783 [==============================] - 373s 477ms/step - loss: 0.0135\n",
      "Epoch 5/5\n",
      "783/783 [==============================] - ETA: 0s - loss: 0.0131\n",
      "----- Generating text after Epoch: 4\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \" place\n",
      "outside of us no conclusion is pe\"\n",
      " place\n",
      "outside of us no conclusion is perture and the for as at are the fand in the sresation of mantor and has that enrethand that the mastertions of are and is a        poner, aw sont anter. the fory and for\n",
      "u senting the a mind that the rentan of the resange of repertion of a deraction of the mould of and and serting the seress and pusestion of manterting and in allation to concinity hamery of the santicity and the peater, in the lom\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \" place\n",
      "outside of us no conclusion is pe\"\n",
      " place\n",
      "outside of us no conclusion is pealt and to dis lparting the gaonity hset there p: that [rilundted, sove more, i mpo8angy\n",
      "hakpous it it sealudion\n",
      "his o ges\n",
      "hhind of unestyingd fis: that not it of, lome, aut antings and wors, the hame the recitionsionicions,\n",
      "aut prrareablenred, that alcomated siitae lumerolt of\n",
      "is yor whom the will\n",
      "sole re, inseltated,\n",
      "the anfucpan it at\n",
      "ere the perireys\n",
      "in the axnenting it minhident, contart of t\n",
      "783/783 [==============================] - 364s 465ms/step - loss: 0.0131\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b70106f2e0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y, epochs=5, batch_size=256,callbacks=desired_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hammingDistance(x,y):\n",
    "    xor = x ^ y\n",
    "    distance = 0\n",
    "    while xor:\n",
    "        # mask out the rest bits\n",
    "        if xor & 1:\n",
    "            distance += 1\n",
    "        xor = xor >> 1\n",
    "    return distance\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 ^ 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 & 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin(4^1).count('1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65536"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 << "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
